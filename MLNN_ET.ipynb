{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d18702-c2ac-4573-8fcb-433ae8cd0364",
   "metadata": {},
   "source": [
    "# Exploring Handwritten Digit Recognition with MNIST #\n",
    "\n",
    "### Introduction ###\n",
    "\n",
    "In this exploration, we delve into the classic challenge of recognizing handwritten digits by employing the MNIST dataset. Our strategy is deliberately streamlined, focusing solely on the use of Dense and Dropout layers within the Keras framework. This investigation is shaped by the methodologies described in François Chollet's foundational text, \"Deep Learning with Python\" (1st edition), blending essential deep learning concepts with actionable insights to effectively direct the development and structure of our neural network.\n",
    "\n",
    "## Dataset Analysis and Setup ##\n",
    "### Overview of the MNIST Dataset ###\n",
    "Renowned for its straightforward nature and educational value, the MNIST dataset comprises grayscale images of handwritten digits. It stands as a cornerstone dataset within the machine learning community, making it an ideal candidate for our investigation, especially given our specific focus on Dense and Dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbe1ccf-82d7-4943-b890-694dd231621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the MNIST Dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd953bb4-0c4e-4b7a-9713-7b5827e77b91",
   "metadata": {},
   "source": [
    "#### Visualising the MNIST Dataset ####\n",
    "Visual representation of data can provide invaluable context and understanding, hence we begin with a visualization of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a72a31b-6c12-4ba6-b342-afb090a50f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualising MNIST Dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Sample images from the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Visualising MNIST Dataset\n",
    "# Sample images from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {train_labels[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35aabb-7b62-4d31-8701-ad1dd0b18c2b",
   "metadata": {},
   "source": [
    "### Data Preprocessing ###\n",
    "Adhering to DLWP's best practices, our preprocessing workflow involves normalizing the pixel values of the images and reshaping them to conform to the neural network's input structure. Additionally, we convert the categorical labels into a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbba788-0480-4252-9b89-1fac21291e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
    "\n",
    "# One-hot encode the labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "val_images = train_images[:10000]\n",
    "val_labels = train_labels[:10000]\n",
    "partial_train_images = train_images[10000:]\n",
    "partial_train_labels = train_labels[10000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143b8aa-e259-430a-b603-91e3fd91a553",
   "metadata": {},
   "source": [
    "### Deciding on the Dataset ###\n",
    "While our primary dataset is MNIST, we considered various datasets appropriate for Dense and Dropout layer models. Structured datasets in CSV format and NLP problems like sentiment analysis are suitable for this type of neural network. Specifically, we explored the prospect of using vectorization methods such as Bag of Words or TF-IDF for NLP tasks. However, for image classification, datasets with minimal diversity like MNIST or Fashion MNIST are preferred, as they facilitate classification without convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14e4a1-20b0-4676-95c0-e3da2292f223",
   "metadata": {},
   "source": [
    "### Choosing the Right Data ###\n",
    "While MNIST is our go-to, we did look around at other datasets that play nice with Dense and Dropout layers. Think structured datasets in CSV or NLP challenges like figuring out if a text is thumbs up or thumbs down. For NLP, we thought about using tricks like Bag of Words or TF-IDF. But when it comes to sorting images, simpler datasets like MNIST or its fashion-forward cousin, Fashion MNIST, make life easier because you don't need those fancy convolutional layers.\n",
    "\n",
    "## Crafting Our Model Development Plan ##\n",
    "### What Counts as Winning ###\n",
    "In this venture, we're all about accuracy: making sure the digits we think we're seeing are the ones actually scribbled down. With 10 different digits to identify, we want to nail the right one each time, straight from the MNIST collection.\n",
    "\n",
    "### How We're Testing Ourselves ###\n",
    "We're sticking to a tried-and-true method: holding some data back (usually around 20%) as a reality check to make sure our model isn't just memorizing but actually learning something useful.\n",
    "\n",
    "### Starting Simple with SLP ###\n",
    "We kick things off with a Single Layer Perceptron (SLP), the simplest of the simple, kind of like logistic regression's younger cousin. It's our yardstick to see if throwing more complex stuff into the mix is really worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93ea10-0fe7-41cf-9bd9-5a9274dedc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "slp_model = models.Sequential([\n",
    "    layers.Input(shape=(28*28,)),  # Input layer specifying the shape of input data\n",
    "    layers.Dense(10, activation='softmax')  # Output layer with 10 units for each class\n",
    "])\n",
    "\n",
    "slp_model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa6515-e2ed-49b6-9e45-2e3443ac7921",
   "metadata": {},
   "source": [
    "#### Visualising the SLP Model ####\n",
    "To understand our model's structure, we generate a visual representation using Keras utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1f8f7-a3fb-49a4-b8d2-5e39450b5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Visualize the SLP model architecture\n",
    "plot_model(slp_model, to_file='slp_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33938593-8cae-4374-884f-d8fc69790ace",
   "metadata": {},
   "source": [
    "### Expanding Model Complexity ###\n",
    "To capture the dataset's nuances and increase our model's predictive power, we introduce additional hidden layers. We have chosen 512 and 256 neurons for our first and second hidden layers, respectively. This choice is guided by common heuristics in neural network design that suggest having larger hidden layers earlier in the network, which can learn a broad array of features before subsequent layers refine these into more specific detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18091d9-455d-405b-b767-a05ef2cbefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model = models.Sequential([\n",
    "    layers.Input(shape=(28 * 28,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "complex_model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7742b8-af85-452c-b170-996d71b1c00e",
   "metadata": {},
   "source": [
    "#### Visualization of the Complex Model ####\n",
    "The architecture of our enhanced model is visualized below, demonstrating the sequential arrangement of dense layers and the transformation of input data through these layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397a6f5-c34b-4b17-8884-a9350c395b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the complex model architecture\n",
    "plot_model(complex_model, to_file='complex_model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ff40c-0646-403f-976a-5d8ad331c0f6",
   "metadata": {},
   "source": [
    "## Training Insights and Model Refinement ##\n",
    "### Understanding Loss Dynamics ###\n",
    "We address phenomena such as the validation loss being lower than the training loss, using intuitive analogies and practical examples to elucidate these observations.\n",
    "\n",
    "### Training Duration and Epochs ###\n",
    "The number of epochs is optimized to allow for early stopping, ensuring the model trains sufficiently without succumbing to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea40ec6-852d-4804-a350-66e236958303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "complex_model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history = complex_model.fit(partial_train_images, partial_train_labels,\n",
    "                            epochs=100, batch_size=128,\n",
    "                            validation_data=(val_images, val_labels),\n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51da333-2e09-483c-8fa2-f781f75a4a02",
   "metadata": {},
   "source": [
    "## Model Regularization and Hyperparameter Tuning ##\n",
    "Regularization is key in preventing overfitting. By adding Dropout layers, we randomly nullify a portion of the outputs from the previous layer during training. This ensures that our network does not become overly reliant on any particular node and can generalize better.\n",
    "\n",
    "### Hyperparameter Optimization ###\n",
    "Systematic exploration of hyperparameter spaces, like learning rate and batch size, allows us to find an optimal configuration. For instance, different learning rates affect the size of the steps taken during gradient descent, while batch size impacts the stability of these steps and the overall speed of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66ca72-b98c-4f62-bf77-a42c0f99fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regularized model\n",
    "regularized_model = models.Sequential([\n",
    "    layers.Input(shape=(28 * 28,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "regularized_model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "# Visualize the complex model architecture\n",
    "plot_model(regularized_model, to_file='complex_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e09e6-e807-4066-9d5d-98b3ec53c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "best_val_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in [0.001, 0.0001]:\n",
    "    for batch_size in [128, 256]:\n",
    "        print(f\"Training with LR={lr}, batch_size={batch_size}\")\n",
    "        model = regularized_model  # Using the model defined above\n",
    "        \n",
    "        history = model.fit(partial_train_images, partial_train_labels, epochs=100, batch_size=batch_size,\n",
    "                            validation_data=(val_images, val_labels), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        val_accuracy = max(history.history['val_accuracy'])\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_params = {'learning_rate': lr, 'batch_size': batch_size}\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_accuracy} with params: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8ee57-d969-4705-a365-83df1f8d8b83",
   "metadata": {},
   "source": [
    "## Training Evaluation ##\n",
    "### Monitoring Model Performance ###\n",
    "We meticulously track training and validation metrics, using visualizations to monitor the model's learning progress and identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19230bbf-162e-4589-ae1e-c17ac153942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "# Extracting the loss and accuracy for training and validation sets\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "# Plotting training and validation loss\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')  # \"bo\" gives blue dot\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')  # \"b\" gives solid blue line\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d97301-94f3-41e6-b8c0-d21f734839d3",
   "metadata": {},
   "source": [
    "### Deciphering Training and Validation Loss Trends ###\n",
    "**Steady Learning Progress**: A consistent decline in training loss tells us the model's getting the hang of the training material.\n",
    "**Off to a Good Start**: The validation loss drops at first, just like the training loss, hinting that the model's getting a good grip on stuff it hasn't seen before right out of the gate.\n",
    "**Overfitting Alert**: But then, the plot thickens. While the training loss keeps shrinking, the validation loss decides it's had enough and starts creeping up. This is our tip-off that the model might be getting a little too cozy with the training data and forgetting how to handle new stuff.\n",
    "**Time to Pump the Brakes?**: That nudge upwards in validation loss is our cue to consider stopping training a bit earlier. Maybe we set up a system where if the validation loss stops improving, we call it a day, ideally right when the validation loss hits its sweet spot.\n",
    "\n",
    "### Parsing Training and Validation Accuracy ###\n",
    "**Rock-Solid Training Accuracy**: This model's acing its training tests, keeping its scores impressively high as it goes.\n",
    "**A Bit of a Wobble in Validation**: On the validation side, things are still looking good, but there's a bit more of a wobble. This suggests our model's a tad less sure-footed when facing new data.\n",
    "**Not Over the Edge Yet**: Since the validation accuracy isn't taking a nosedive, we're not in the danger zone of overfitting to the training set by the end.\n",
    "**Room for a Little Tweaking**: Those ups and downs in validation accuracy might smooth out with a bit of tuning, like adjusting the learning rate or experimenting with different optimizers or more regularization.\n",
    "\n",
    "### Pathways to Polish ###\n",
    "**Dialing in the Hyperparameters**: A deeper dive into hyperparameter tuning might just unearth some gains, especially with that validation accuracy playing hard to get.\n",
    "**Mixing Up the Data**: If it fits the bill, shaking up the data with some augmentation techniques could give our model a better shot at handling diverse scenarios, leading to steadier accuracy and loss figures.\n",
    "**Layering on More Regularization**: Beyond Dropout, we could look into L1 or L2 regularization for those dense layers to keep overfitting in check.\n",
    "**A Smarter Stop Sign**: Refining the early stopping strategy to also keep an eye on validation accuracy could ensure we preserve the model's knack for generalizing well.\n",
    "With these insights in hand, we're all set to fine-tune our approach, aiming for a model that not only fits like a glove to the training data but also welcomes new data with open arms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19430a-0e1a-4e79-87fd-bc1ab7718be7",
   "metadata": {},
   "source": [
    "## Wrapping Up and What's Next ##\n",
    "We've navigated through the twists and turns of classifying those tricky handwritten digits, all while sticking to our game plan of using just Dense and Dropout layers. This tale of trial, error, and eventual triumph is a testament to the iterative dance of machine learning, grounded in solid principles yet always open to a bit of creative problem-solving.\n",
    "\n",
    "### On the Horizon ###\n",
    "As we look to the future, we're excited about the prospects of dialing up the complexity. We're thinking about throwing in some data augmentation to give our model a richer learning experience, or maybe even dabbling in transfer learning to stand on the shoulders of machine learning giants. The journey continues, and the possibilities are as thrilling as ever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a626d-ff87-4c7e-8723-a35ae2269172",
   "metadata": {},
   "source": [
    "## References ##\n",
    "*Chollet, F. (2018). Deep Learning with Python. Shelter Island (New York, Estados Unidos): Manning, Cop.*\n",
    "\n",
    "*Abadi, Mart&#x27;in et al., 2016. Tensorflow: A system for large-scale machine learning. In 12th $USENIX$ Symposium on Operating Systems Design and Implementation ($OSDI$ 16). pp. 265–283.*\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
